{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/81300/AI-Notebooks/blob/testing/Colab-TextGen-GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Alternative PygmalionAI notebook for Google Colab\n",
        "\n",
        "Version: GPU\n",
        "\n",
        "This notebook is an *unofficial* method to run [PygmalionAI LLMs](https://github.com/PygmalionAI) (NSFW) that uses **oobabooga**'s [text-generation-webui project](https://github.com/oobabooga/text-generation-webui) in chat mode.\n",
        "\n",
        "Run all the cells and a public gradio URL will appear at the bottom.\n",
        "\n",
        "You can create your own custom characters using the [Pygmalion JSON character creator](https://oobabooga.github.io/character-creator.html). If you enable Google Drive you can also upload them to the following location:\n",
        "  * [**Google Drive**](https://drive.google.com/) &rarr; **My Drive** &rarr; **Colab-TextGen** &rarr; **characters**"
      ],
      "metadata": {
        "id": "MFQl6-FjSYtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1. Keep this tab alive to prevent Colab from disconnecting you { display-mode: \"form\" }\n",
        "\n",
        "# From: https://github.com/henk717/KoboldAI\n",
        "#@markdown Press play on the music player to keep the tab alive (Uses only 13MB of data).\n",
        "%%html\n",
        "<audio src=\"https://henk.tech/colabkobold/silence.m4a\" controls>"
      ],
      "metadata": {
        "id": "f7TVVj_z4flw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Clone the repository and install dependencies\n",
        "\n",
        "Enable_Google_Drive = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown After this cell completes you should click on the **Restart runtime** button if it appears, then move on to step 3.\n",
        "\n",
        "\n",
        "if Enable_Google_Drive:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "else:\n",
        "  import os\n",
        "  if not os.path.exists(\"/content/drive\"):\n",
        "    os.mkdir(\"/content/drive\")\n",
        "  if not os.path.exists(\"/content/drive/MyDrive/\"):\n",
        "    os.mkdir(\"/content/drive/MyDrive/\")\n",
        "\n",
        "# Download Github repo\n",
        "!git -C /content/drive/MyDrive/Colab-TextGen pull || git clone https://github.com/81300/text-generation-webui /content/drive/MyDrive/Colab-TextGen\n",
        "%cd /content/drive/MyDrive/Colab-TextGen\n",
        "!git switch autodevices\n",
        "\n",
        "# Install requirements\n",
        "%cd /content/drive/MyDrive/Colab-TextGen\n",
        "!pip install --upgrade --no-cache-dir --progress-bar=off -r requirements.txt\n",
        "!pip install --upgrade --no-cache-dir --progress-bar=off diffusers deepspeed\n",
        "!pip install --upgrade --no-cache-dir --progress-bar=off Pillow==9.2.0\n",
        "!DEBIAN_FRONTEND=noninteractive apt-get update\n",
        "!DEBIAN_FRONTEND=noninteractive apt-get install -y libaio-dev"
      ],
      "metadata": {
        "id": "F1mssJmZ5BMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. Select a model\n",
        "\n",
        "Model = \"Pygmalion 6B\" #@param [\"Pygmalion 6B\", \"Pygmalion 6B experimental\", \"Pygmalion 2.7B\", \"Pygmalion 1.3B\", \"Pygmalion 350M\"] {allow-input: false}\n",
        "Reshard_model = True #@param {type: \"boolean\"}\n",
        "Max_shard_size = \"5GB\" #@param [\"10GB\", \"5GB\", \"3GB\", \"1GB\"] {allow-input: false}\n",
        "Model_storage = \"Colab runtime\" #@param [\"Colab runtime\", \"Google Drive\"] {allow-input: false}\n",
        "\n",
        "\n",
        "if Model == \"Pygmalion 6B\":\n",
        "  huggingface_org = \"PygmalionAI\"\n",
        "  huggingface_repo = \"pygmalion-6b\"\n",
        "  huggingface_branch = \"main\"\n",
        "  model_name = \"pygmalion-6b\"\n",
        "elif Model == \"Pygmalion 6B experimental\":\n",
        "  huggingface_org = \"PygmalionAI\"\n",
        "  huggingface_repo = \"pygmalion-6b\"\n",
        "  huggingface_branch = \"dev\"\n",
        "  model_name = \"pygmalion-6b_dev\"\n",
        "elif Model == \"Pygmalion 2.7B\":\n",
        "  huggingface_org = \"PygmalionAI\"\n",
        "  huggingface_repo = \"pygmalion-2.7b\"\n",
        "  huggingface_branch = \"main\"\n",
        "  model_name = \"pygmalion-2.7b\"\n",
        "elif Model == \"Pygmalion 1.3B\":\n",
        "  huggingface_org = \"PygmalionAI\"\n",
        "  huggingface_repo = \"pygmalion-1.3b\"\n",
        "  huggingface_branch = \"main\"\n",
        "  model_name = \"pygmalion-1.3b\"\n",
        "elif Model == \"Pygmalion 350M\":\n",
        "  huggingface_org = \"PygmalionAI\"\n",
        "  huggingface_repo = \"pygmalion-350m\"\n",
        "  huggingface_branch = \"main\"\n",
        "  model_name = \"pygmalion-350m\"\n",
        "\n",
        "import os\n",
        "offload_path = \"/content/offload\"\n",
        "if not os.path.exists(offload_path):\n",
        "  os.makedirs(offload_path)\n",
        "moodels_path = \"/content/models\"\n",
        "if not os.path.exists(moodels_path):\n",
        "  os.makedirs(moodels_path)\n",
        "\n",
        "# Download and prepare model\n",
        "%cd /content\n",
        "![[ ! -f models/$model_name/config.json ]] && python /content/drive/MyDrive/Colab-TextGen/download-model.py $huggingface_org/$huggingface_repo --branch $huggingface_branch\n",
        "\n",
        "if Reshard_model:\n",
        "  import torch\n",
        "  import diffusers\n",
        "  from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "  original_model = model_name\n",
        "  resharded_model = model_name + f'_resharded'\n",
        "  launch_model = resharded_model\n",
        "  reshard_src_path = \"/content/models/\" + original_model\n",
        "  reshard_out_path = \"/content/models/\" + resharded_model\n",
        "  if not os.path.exists(reshard_out_path):\n",
        "    os.makedirs(reshard_out_path)\n",
        "  if os.path.exists(reshard_src_path):\n",
        "    import gc\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    model = AutoModelForCausalLM.from_pretrained(reshard_src_path, torch_dtype=\"auto\", low_cpu_mem_usage=True).cuda()\n",
        "    tokenizer = AutoTokenizer.from_pretrained(reshard_src_path)\n",
        "    model.save_pretrained(reshard_out_path, max_shard_size=Max_shard_size)\n",
        "    tokenizer.save_pretrained(reshard_out_path)\n",
        "else:\n",
        "  launch_model = model_name\n",
        "\n",
        "![[ \"$Model_storage\" = \"Google Drive\" ]] \\\n",
        "  && mv -f /content/models/$launch_model /content/drive/MyDrive/Colab-TextGen/models/$launch_model\n",
        "![[ \"$Model_storage\" = \"Colab runtime\" ]] \\\n",
        "  && mkdir -p /content/drive/MyDrive/Colab-TextGen/models/$launch_model \\\n",
        "  && mount --bind /content/models/$launch_model /content/drive/MyDrive/Colab-TextGen/models/$launch_model"
      ],
      "metadata": {
        "id": "yyl9TGSoRIwV",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4. Launch the web interface\n",
        "\n",
        "%cd /content/drive/MyDrive/Colab-TextGen\n",
        "import gc\n",
        "gc.collect()\n",
        "!LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/lib64-nvidia python server.py --share --cai-chat --no-stream --model $launch_model"
      ],
      "metadata": {
        "id": "txeAxCGyRK1F",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cleanup all models\n",
        "\n",
        "#@markdown Free up space within the current runtime. After this completes run step 4 again.\n",
        "\n",
        "!find /content/models -mindepth 1 -maxdepth 1 -type d -exec rm -rv \"{}\" \\;\n",
        "!find /content/torch-dumps -mindepth 1 -exec rm -rv \"{}\" \\;"
      ],
      "metadata": {
        "cellView": "form",
        "id": "XbKanChesbUM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}